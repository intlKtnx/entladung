{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "from torch.utils import data\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix,  ConfusionMatrixDisplay\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8694bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping the dataset with load function\n",
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        super().__init__()\n",
    "        self.train_data_cache = []\n",
    "        self.test_data_cache = []\n",
    "        self.manual_data_cache = []\n",
    "        self.full_test_data_cache = []\n",
    "        self.transform = transform\n",
    "        self.label_count = [0, 0, 0]\n",
    "        # Search for all h5 files\n",
    "        p = Path(file_path)\n",
    "        files = p.glob('normalized*512.h5')\n",
    "        logging.debug(files)\n",
    "        for h5dataset_fp in files:\n",
    "            logging.debug(h5dataset_fp)\n",
    "            with h5py.File(h5dataset_fp.resolve()) as h5_file:\n",
    "                # Walk through all groups, extracting datasets\n",
    "                for gname, group in h5_file.items():\n",
    "                    k = 0\n",
    "                    j = 0\n",
    "                    l = 0\n",
    "                    if gname == 'referenz':\n",
    "                        label = 0\n",
    "                    elif gname == 'spitze':\n",
    "                        label = 1\n",
    "                    elif gname == 'grenzflaeche':\n",
    "                        label = 2\n",
    "\n",
    "                    logging.debug(group.items())\n",
    "                    for dname, ds in tqdm(group.items()):\n",
    "                        if k < 3000:\n",
    "                            for i in np.split(ds, 2):\n",
    "                                self.train_data_cache.append([label, torch.tensor(i).unsqueeze(0).type(torch.float32)])\n",
    "                            k += 1\n",
    "                        elif j < 400:\n",
    "                            self.full_test_data_cache.append([label, ds])\n",
    "                            for i in np.split(ds, 2):\n",
    "                                self.test_data_cache.append([label, torch.tensor(i).unsqueeze(0).type(torch.float32)])\n",
    "                            j += 1\n",
    "                        elif l < 100:\n",
    "                            for i in np.split(ds, 2):\n",
    "                                self.manual_data_cache.append([label, torch.tensor(i).unsqueeze(0).type(torch.float32)])\n",
    "                            l += 1\n",
    "                        if k == 3000 and j == 400 and l == 100:\n",
    "                            break\n",
    "                                \n",
    "    def __getitem__(self, index):\n",
    "        return self.data_cache[index]\n",
    "\n",
    "    def get_test_data(self):\n",
    "        return self.test_data_cache\n",
    "\n",
    "    def get_train_data(self):\n",
    "        return self.train_data_cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ba60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 2, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(2, 4, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(4, 8, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(8, 16, kernel_size=3, padding=1)  # endsize 1536 maxpool 3\n",
    "        # self.conv5 = nn.Conv1d(128, 256, kernel_size=3, padding=1) #endsize 1024 maxpool 3\n",
    "        # self.conv6 = nn.Conv1d(256, 512, kernel_size=3, padding=1) # endsize 512 maxpool 3\n",
    "\n",
    "        self.fc1 = nn.Linear(48, 3) #input 1000 / 4 384//8\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool1d(F.relu(self.conv1(x)), 3)\n",
    "        x = F.max_pool1d(F.relu(self.conv2(x)), 3)\n",
    "        x = F.max_pool1d(F.relu(self.conv3(x)), 3)\n",
    "        x = F.max_pool1d(F.relu(self.conv4(x)), 3)\n",
    "        # x = F.max_pool1d(F.relu(self.conv5(x)),3)\n",
    "        # x = F.max_pool1d(F.relu(self.conv6(x)),3)\n",
    "        #logging.debug(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        #logging.debug(x.shape)\n",
    "        x = F.softmax(self.fc1(x), dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "customData = CustomDataset(\"/home/marcus/Dokumente/entladung/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the train loop\n",
    "def train(dataloader, optimizer, criterion, model):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    j = 0\n",
    "    loss_values = []\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [labels, inputs]\n",
    "\n",
    "        inputs = data[1]\n",
    "        labels = data[0]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_values.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # log statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:\n",
    "            print(f\"[{epoch}]Loss: {running_loss / 500} \")\n",
    "        \n",
    "    print(f\"[{epoch}] Train Loss: {running_loss / (i+1)} \") \n",
    "    plt.plot(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fa49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the accuracy on single 1024 snippets\n",
    "def split_test(dataloader,criterion, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    ACC = []\n",
    "    true = []\n",
    "    pred = []\n",
    "    right_pred = []\n",
    "    wrong_pred = []\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for labels, inputs in dataloader:\n",
    "            labels, inputs = labels.to(device), inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            ACC.append((torch.argmax(outputs,axis=1)==labels).float().mean().item())\n",
    "            pred.extend(list((torch.argmax(outputs,axis=1).cpu().numpy())))\n",
    "            true.extend(list(labels.cpu().numpy()))\n",
    "            correct += (outputs.argmax(1) == labels).type(torch.float).sum().item()\n",
    "            for i, output in enumerate(outputs):\n",
    "                if output.argmax(0) != labels[i]:\n",
    "                    wrong_pred.append([inputs[i], labels[i], output])\n",
    "                elif output.argmax(0) == labels[i]:\n",
    "                    right_pred.append([inputs[i], labels[i], output])\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\" Random TeilstÃ¼ck Error: Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "    return confusion_matrix(true, pred), confusion_matrix(true, pred, normalize='true'), wrong_pred, right_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42030a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_complete(dataloader, optimizer, criterion, model):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    size = len(dataloader.dataset)\n",
    "    correct = 0\n",
    "    ACC = []\n",
    "    true = []\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for labels, inputs in dataloader:\n",
    "            labels = labels.to(device)\n",
    "            outputs = np.array([])\n",
    "            for sample in inputs:\n",
    "                #splitted_input = torch.reshape(sample, (4, 250)).unsqueeze(0).to(device)\n",
    "                splitted_input \n",
    "                splitted_output = model(splitted_input)\n",
    "                answer_count = np.array([0,0,0])\n",
    "                for i in splitted_output:\n",
    "                    answer_count[i.argmax(0)] += 1\n",
    "                #print(answer_count, answer_count.sum())\n",
    "                outputs = np.append(outputs, answer_count.argmax(0))\n",
    "                ACC.append((torch.argmax(outputs,axis=1)==labels).float().mean().item())\n",
    "                pred.extend(list((torch.argmax(outputs,axis=1).cpu().numpy())))\n",
    "                true.extend(list(labels.cpu().numpy()))\n",
    "            for i in range(len(outputs)):\n",
    "                if outputs[i] == labels[i]:\n",
    "                    correct += 1\n",
    "            #correct += (outputs == labels).type(torch.float).sum().item()\n",
    "    correct /= size\n",
    "    print(f\"Full Sample Error: Accuracy: {(100*correct):>0.1f}%\")\n",
    "    return confusion_matrix(true, pred), confusion_matrix(true, pred, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bcb720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for cuda device and selecting it if possible\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model and moving it to the correct device\n",
    "model = Network().to(device)\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train and test sets\n",
    "train_data = customData.get_train_data()\n",
    "test_data = customData.get_test_data()\n",
    "full_test_data = customData.full_test_data_cache\n",
    "full_test_data = DataLoader(full_test_data, batch_size=64, shuffle=True, pin_memory=False, num_workers=0)\n",
    "train_dataloader = DataLoader(train_data, batch_size=256, shuffle=True, pin_memory=False, num_workers=0)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True, pin_memory=False, num_workers=0)\n",
    "manual_dataloader = DataLoader(customData.manual_data_cache, batch_size=4, shuffle=False, pin_memory=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8cb51b-f63d-4fb0-a50d-8329714f4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cache=[]\n",
    "for i, val in enumerate( train_data):\n",
    "        train_data[i][0]\n",
    "        cache.append(train_data[i][0])\n",
    "    \n",
    "print(Counter(cache).keys())\n",
    "print(Counter(cache).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache=[]\n",
    "for i, val in enumerate( test_data):\n",
    "        test_data[i][0]\n",
    "        cache.append(test_data[i][0])\n",
    "    \n",
    "print(Counter(cache).keys())\n",
    "print(Counter(cache).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9d735-8b75-47d6-ab4b-663cb2021d57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    loss_values=train(train_dataloader, optimizer, criterion, model)\n",
    "    CM=split_test(test_dataloader, criterion, model)\n",
    "    #CM2=test_complete(test_dataloader, optimizer, criterion, model)\n",
    "print('Finished Training')\n",
    "#print(CM[0])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=CM[0],display_labels=[0, 1, 2])\n",
    "disp.plot()\n",
    "plt.show()\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=CM[1],display_labels=[0, 1, 2])\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bee523",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(title=\"spitze labeled referenz\")\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(title=\"referenz labeled spitze\")\n",
    "j = 0\n",
    "k = 0\n",
    "for i in CM[2]:\n",
    "    if i[1].item() == 1 and i[2].argmax(0).item() == 0 and k < 2:\n",
    "        ax1.plot(range(len(i[0][0])), i[0][0].cpu())\n",
    "        k += 1\n",
    "        print(i[2])\n",
    "    elif i[1].item() == 0 and i[2].argmax(0).item() == 1 and j < 2:\n",
    "        ax2.plot(range(len(i[0][0])), i[0][0].cpu())\n",
    "        j += 1\n",
    "        print(i[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113bcdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(title=\"spitze labeled spitze\")\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(title=\"referenz labeled referenz\")\n",
    "j = 0\n",
    "k = 0\n",
    "for i in CM[3]:\n",
    "    if i[1].item() == 1 and i[2].argmax(0).item() == 1 and k < 2:\n",
    "        ax1.plot(range(len(i[0][0])), i[0][0].cpu())\n",
    "        k += 1\n",
    "        print(i[2])\n",
    "    elif i[1].item() == 0 and i[2].argmax(0).item() == 0 and j < 2:\n",
    "        ax2.plot(range(len(i[0][0])), i[0][0].cpu())\n",
    "        j += 1\n",
    "        print(i[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b2541",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for labels, inputs in manual_dataloader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    logging.debug(model(inputs), labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed44a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.get_state()\n",
    "print(seed[1])\n",
    "df = pd.DataFrame(data = seed[1])\n",
    "df.to_csv(\"entladung_randomseed3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5247fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/home/marcus/Dokumente/entladung/best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dd6ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}